{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a5c9ae5",
   "metadata": {},
   "source": [
    "### Converting into pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1103070b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from docx2pdf import convert\n",
    "from PyPDF2 import PdfReader,PdfWriter#manipulating the pdf\n",
    "from reportlab.lib.pagesizes import A4 #creating from scratch and manipulating the pdfs\n",
    "from reportlab.pdfgen import canvas# canvas provides a flexible way to place text, images, graphics, and other elements at specific positions on the PDF page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "584eebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert docx to pdf\n",
    "def convert_docx_to_pdf(doc_file,output_pdf):\n",
    "    convert(doc_file,output_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3929468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert text to pdf\n",
    "def convert_text_to_pdf(text_file,output_pdf):\n",
    "    with open(text_file,'r') as file:\n",
    "        text=file.read()\n",
    "        #creating the outputpdf layout\n",
    "        c = canvas.Canvas(output_pdf, pagesize=A4)\n",
    "        width, height = A4\n",
    "        top_margin=height-50\n",
    "        left_margin=50\n",
    "        lines=text.split('\\n')\n",
    "        for line in lines:\n",
    "            c.drawString(left_margin,top_margin,line)\n",
    "            top_margin-=15\n",
    "        c.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e5e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coping the pdf files to another folder\n",
    "def copy_pdf_to_folder(pdf_file, output_folder):\n",
    "    pdf_reader = PdfReader(pdf_file)\n",
    "    pdf_writer = PdfWriter()\n",
    "\n",
    "    for page in pdf_reader.pages:\n",
    "        pdf_writer.add_page(page)\n",
    "\n",
    "    output_pdf = os.path.join(output_folder, os.path.basename(pdf_file))\n",
    "    with open(output_pdf, 'wb') as f:\n",
    "        pdf_writer.write(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f6b1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed. PDFs are saved in the output folder.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"C:/Users/user/Desktop/resumes\"\n",
    "    output_folder = \"C:/Users/user/Desktop/pdfresumes\"\n",
    "    #creates a folder if it doesnot exits\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        if filename.lower().endswith(\".txt\"):\n",
    "            output_pdf = os.path.join(output_folder, filename.replace(\".txt\", \".pdf\"))\n",
    "            convert_text_to_pdf(file_path, output_pdf)\n",
    "\n",
    "        elif filename.lower().endswith(\".docx\"):\n",
    "            output_pdf = os.path.join(output_folder, filename.replace(\".docx\", \".pdf\"))\n",
    "            convert_docx_to_pdf(file_path, output_pdf)\n",
    "\n",
    "        elif filename.lower().endswith(\".pdf\"):\n",
    "            copy_pdf_to_folder(file_path, output_folder)\n",
    "\n",
    "    print(\"Conversion completed. PDFs are saved in the output folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95542c82",
   "metadata": {},
   "source": [
    "### By using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a00ec3",
   "metadata": {},
   "source": [
    "### Extracting the information of name,email,skills,phonenumber from the resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "358633a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import PyPDF2\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "# Download missing NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f87d6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume: Alice Johnson.pdf\n",
      "Name: Alice Johnson\n",
      "Email: alice.johnson@email.com\n",
      "Skills (NLTK): Social Media Platforms, Twitter Analytics, Elm Street, BBA, Anytown, Google Analytics, Johnson, Facebook Insights Content, USA, ROI, Instagram, Campaign, Influencer, Business Administration, Email, Alice, Anytown University, Digital\n",
      "------------------------------\n",
      "Resume: Daniel Cooper.pdf\n",
      "Name: Daniel Cooper\n",
      "Email: daniel.cooper@email.com\n",
      "Skills (NLTK): Microsoft Excel, Product Launch, Daniel, Salesforce Data Analysis, BBA, Sunflower Lane, Negotiation, Key, USA, Sales CRM, Meadowville University, Business Administration, Meadowville, Sales Manager Dynamic Solutions, New, Account Management\n",
      "------------------------------\n",
      "Resume: David Wilson.pdf\n",
      "Name: David Wilson\n",
      "Email: david.wilson@email.com\n",
      "Skills (NLTK): Education, ESL, Oakwood Drive, Grades, USA, David, English, Suburbia College, School Teacher, ABC Elementary School, Suburbia, Objective, Wilson, Improvement Program, State Teaching Certification\n",
      "------------------------------\n",
      "Resume: Emily Chen.pdf\n",
      "Name: Emily Chen\n",
      "Email: emily.chen@email.com\n",
      "Skills (NLTK): Data, Matplotlib, Townsville, Science, Townsville University, Tableau Machine, Segmentation, Seaborn, USA, Data Analyst Intern Data Insights Company, Tableau, Pandas, Classification, Python, Customer, R Data, NumPy, Model\n",
      "------------------------------\n",
      "Resume: Emma Adams.pdf\n",
      "Name: Emma Adams\n",
      "Email: emma.adams@email.com\n",
      "Skills (NLTK): Emma, Microsoft Excel, Conference, Negotiation, USA, Cvent Budgeting, Email, Mountainville, Hospitality Management Mountainville College, Celebration\n",
      "------------------------------\n",
      "Resume: John Doe.pdf\n",
      "Name: John Doe\n",
      "Email: john.doe@email.com\n",
      "Skills (NLTK): OCJD, ABC Tech Solutions, WebSocket, John, Flask, APIs, City, PostgreSQL Version, Highly, Objective, Oracle Certified Java Developer, Java, Computer Science, State, JavaScript Frameworks, Software Engineer, Python, Website, AWS, ZIP, Science, Main Street, Django, Docker, XYZ University\n",
      "------------------------------\n",
      "Resume: Michael Smith.pdf\n",
      "Name: Michael Smith\n",
      "Email: michael.smith@email.com\n",
      "Skills (NLTK): MongoDB, Scrum Master Certification, MySQL, Python Web, CSS, APIs, Software Engineer Tech Innovators, Hibernate, Online, Objective, Java, Oak Avenue, State, CSM, Michael, Cityville, JavaScript Frameworks, Programmer, Computer Science City University, Science, Upgrade, Oracle Certified Professional, Java SE\n",
      "------------------------------\n",
      "Resume: Olivia Martinez.pdf\n",
      "Name: Olivia Martinez\n",
      "Email: olivia.martinez@email.com\n",
      "Skills (NLTK): Microsoft Office, Excel, Business Administration Rivertown, Phone Etiquette, PowerPoint, USA, Assistant, Client Relationship Management, Email, Olivia, Highly, Willow Avenue, Word, Database Management, ABC Corporation, Rivertown, Associate Degree\n",
      "------------------------------\n",
      "Resume: Robert Davis.pdf\n",
      "Name: Robert Davis\n",
      "Email: robert.davis@email.com\n",
      "Skills (NLTK): DFM, Metroville, Pine Street, Science, Metroville University, COMSOL, Mechanical, State, Automation, CAD, Plastics Product, AutoCAD Simulation, Objective, Handheld, Manufacturability, Robert\n",
      "------------------------------\n",
      "Resume: Sophia Lee.pdf\n",
      "Name: Sophia Lee\n",
      "Email: sophia.lee@email.com\n",
      "Skills (NLTK): Adobe Photoshop Layout, USA, Graphic, Sketch, Adobe InDesign, Cherry Lane, BFA, Adobe XD, Objective, Villageland, Identity Redesign, Graphic Designer Creative Studio, Fine Arts, Website, Sophia, Brand, Graphic Design Software, Adobe Illustrator, Redesign\n",
      "------------------------------\n",
      "Resume: William Turner.pdf\n",
      "Name: William Turner\n",
      "Email: william.turner@email.com\n",
      "Skills (NLTK): William, Film, Video Editing Software, Video Editor Creative Studios, Film Production, USA, Adobe Premiere Pro, Effects Sound, Final Cut Pro, Campaigns, Highly, Seaside Town, Adobe Audition, Arts, Harbor View\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to extract skills using NLTK\n",
    "def extract_skills_nltk(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    skills = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        tagged_words = pos_tag(words)\n",
    "        named_entities = ne_chunk(tagged_words)\n",
    "        \n",
    "        for entity in named_entities:\n",
    "            if isinstance(entity, nltk.Tree):\n",
    "                skill = \" \".join([word for word, tag in entity.leaves()])\n",
    "                if any(tag == 'NNP' for word, tag in entity.leaves()):\n",
    "                    skills.append(skill)\n",
    "    \n",
    "    return list(set(skills))\n",
    "\n",
    "# Function to extract contact details using regular expressions\n",
    "def extract_contact_info(text):\n",
    "    name = re.findall(r'^[A-Z][a-zA-Z]+(?:\\s[A-Z][a-zA-Z]+)*', text)\n",
    "    email = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
    "    return name, email\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resume_folder = \"C:/Users/user/Desktop/pdfresumes\"\n",
    "    resumes = []\n",
    "    \n",
    "    for filename in os.listdir(resume_folder):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            with open(os.path.join(resume_folder, filename), \"rb\") as resume_file:\n",
    "                pdf_reader = PyPDF2.PdfReader(resume_file)\n",
    "                text = \"\"\n",
    "                for page in pdf_reader.pages:\n",
    "                    text += page.extract_text()\n",
    "                resumes.append({\"filename\": filename, \"text\": text})\n",
    "\n",
    "    # Step 3: Text Analysis - Extract skills and details\n",
    "    for resume in resumes:\n",
    "        resume[\"skills\"] = extract_skills_nltk(resume[\"text\"])\n",
    "        name, email = extract_contact_info(resume[\"text\"])\n",
    "        resume[\"name\"] = name[0] if name else \"Not Found\"\n",
    "        resume[\"email\"] = email[0] if email else \"Not Found\"\n",
    "\n",
    "    # Print details of all resumes\n",
    "    for resume in resumes:\n",
    "        print(f\"Resume: {resume['filename']}\")\n",
    "        print(\"Name:\", resume[\"name\"])\n",
    "        print(\"Email:\", resume[\"email\"])\n",
    "        print(\"Skills (NLTK):\", \", \".join(resume[\"skills\"]))\n",
    "        print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdcea05",
   "metadata": {},
   "source": [
    "### Extracting the Resume score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fd31b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea5fef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_file):\n",
    "    pdf_reader = PdfReader(pdf_file)\n",
    "    text_content = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text_content += page.extract_text()\n",
    "    return text_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8874ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    resume_folder = \"C:/Users/user/Desktop/pdfresumes\"\n",
    "    resumes = []\n",
    "    for filename in os.listdir(resume_folder):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            with open(os.path.join(resume_folder, filename), \"rb\") as resume_file:\n",
    "                pdf_reader = PdfReader(resume_file)\n",
    "                text = \"\"\n",
    "                for page in range(len(pdf_reader.pages)):\n",
    "                    text += pdf_reader.pages[page].extract_text()\n",
    "                resumes.append({\"filename\": filename, \"text\": text})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54b955f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the desired skills (comma-separated): c,java,html,css,python\n"
     ]
    }
   ],
   "source": [
    "# Define the skill sets you are looking for\n",
    "desired_skills = input(\"Enter the desired skills (comma-separated): \").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "881231da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Analysis and Score Calculation\n",
    "for resume in resumes:\n",
    "    skills_found = [skill for skill in desired_skills if skill.lower() in resume[\"text\"].lower()]\n",
    "    resume[\"score\"] = len(skills_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "688811f6",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Ranking\n",
    "resumes.sort(key=lambda x: x[\"score\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "595f29fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Smith.pdf - Score: 5\n",
      "John Doe.pdf - Score: 3\n",
      "Emily Chen.pdf - Score: 2\n",
      "Alice Johnson.pdf - Score: 1\n",
      "Daniel Cooper.pdf - Score: 1\n",
      "David Wilson.pdf - Score: 1\n",
      "Emma Adams.pdf - Score: 1\n",
      "Olivia Martinez.pdf - Score: 1\n",
      "Robert Davis.pdf - Score: 1\n",
      "Sophia Lee.pdf - Score: 1\n",
      "William Turner.pdf - Score: 1\n"
     ]
    }
   ],
   "source": [
    "#Visualization\n",
    "for resume in resumes:\n",
    "    print(f\"{resume['filename']} - Score: {resume['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2793b103",
   "metadata": {},
   "source": [
    "### Extract the details of the perfect candidate for the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de9539be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of the resumes with the highest score:\n",
      "Resume: Michael Smith.pdf\n",
      "Name: Michael Smith\n",
      "Address: 456 Oak Avenue, Cityville, State\n",
      "Phone Number: Not Found\n",
      "Email: michael.smith@email.com\n",
      "Skills (NLTK): MongoDB, Scrum Master Certification, MySQL, Python Web, CSS, APIs, Software Engineer Tech Innovators, Hibernate, Online, Objective, Java, Oak Avenue, State, CSM, Michael, Cityville, JavaScript Frameworks, Programmer, Computer Science City University, Science, Upgrade, Oracle Certified Professional, Java SE\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to extract contact details using regular expressions\n",
    "def extract_contact_info(text):\n",
    "    name = re.findall(r'^[A-Z][a-zA-Z]+(?:\\s[A-Z][a-zA-Z]+)*', text)\n",
    "    email = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
    "    phone_number = re.findall(r'\\b\\d{10}\\b', text)\n",
    "    address = re.findall(r'\\b\\d+\\s+[^,\\n]+,[^,\\n]+,[^,\\n]+\\b', text)\n",
    "    return name, email, phone_number, address\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resume_folder = \"C:/Users/user/Desktop/pdfresumes\"\n",
    "    resumes = []\n",
    "    \n",
    "    for filename in os.listdir(resume_folder):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            with open(os.path.join(resume_folder, filename), \"rb\") as resume_file:\n",
    "                pdf_reader = PyPDF2.PdfReader(resume_file)\n",
    "                text = \"\"\n",
    "                for page in pdf_reader.pages:\n",
    "                    text += page.extract_text()\n",
    "                resumes.append({\"filename\": filename, \"text\": text})\n",
    "\n",
    "    #  Text Analysis and Score Calculation\n",
    "    for resume in resumes:\n",
    "        skills_found = [skill.strip().lower() for skill in desired_skills if skill.strip().lower() in resume[\"text\"].lower()]\n",
    "        resume[\"score\"] = len(skills_found)\n",
    "\n",
    "    #  Find the maximum score\n",
    "    max_score = max(resume[\"score\"] for resume in resumes)\n",
    "\n",
    "    # Extract and Print details of all resumes with the highest score\n",
    "    print(\"Details of the resumes with the highest score:\")\n",
    "    for resume in resumes:\n",
    "        if resume[\"score\"] == max_score:\n",
    "            skills_nltk = extract_skills_nltk(resume[\"text\"])\n",
    "            name, email, phone_number, address = extract_contact_info(resume[\"text\"])\n",
    "            \n",
    "            print(f\"Resume: {resume['filename']}\")\n",
    "            print(\"Name:\", name[0] if name else \"Not Found\")\n",
    "            print(\"Address:\", address[0] if address else \"Not Found\")\n",
    "            print(\"Phone Number:\", phone_number[0] if phone_number else \"Not Found\")\n",
    "            print(\"Email:\", email[0] if email else \"Not Found\")\n",
    "            print(\"Skills (NLTK):\", \", \".join(skills_nltk))\n",
    "            print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76926f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
